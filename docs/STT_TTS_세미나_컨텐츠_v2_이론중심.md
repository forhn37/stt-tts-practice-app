# 🎙️ 소리와 언어의 연결: STT & TTS 원리 탐구

> **세미나 정보**
> - 일시: 2024년 12월 20일
> - 대상: 개발자 및 현업 종사자
> - 소요시간: 약 2시간
> - 강사: [강사명]

---

## 📋 목차

1. **[기반 지식]** 컴퓨터는 소리를 어떻게 이해하는가? (25분)
2. **[STT 심화]** 불규칙한 소리를 규칙적인 텍스트로 (30분)
3. ☕ 휴식 (10분)
4. **[TTS 심화]** 텍스트에 생명(운율)을 불어넣기 (25분)
5. **[실무/응용]** 개발자가 알아야 할 평가지표와 이슈 (20분)
6. Q&A (10분)

---

# Chapter 1. 컴퓨터는 소리를 어떻게 이해하는가?

> **핵심 질문**: 연속적인 아날로그 소리를 어떻게 컴퓨터가 처리할 수 있는 형태로 바꿀까?

---

## 1.1 소리란 무엇인가?

### 소리의 본질

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│    🗣️ ─────▶  ≋≋≋≋≋≋≋≋≋≋≋ ─────▶ 👂                   │
│   발성         공기 진동 (압력파)      청취              │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

소리는 **공기 분자의 진동**으로 발생하는 압력파입니다.

**소리의 3요소**:

| 요소 | 물리적 특성 | 우리가 느끼는 것 |
|------|-----------|----------------|
| **진폭 (Amplitude)** | 파동의 높이 | 소리의 크기 (볼륨) |
| **주파수 (Frequency)** | 1초당 진동 횟수 | 소리의 높낮이 (피치) |
| **파형 (Waveform)** | 파동의 모양 | 음색 (악기/목소리 구분) |

---

### 아날로그 vs 디지털

```
┌─────────────────────────────────────────────────────────┐
│  아날로그 신호                                           │
│                                                         │
│      ∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿                              │
│      연속적인 곡선 (무한한 값)                            │
│                                                         │
├─────────────────────────────────────────────────────────┤
│  디지털 신호                                             │
│                                                         │
│      ▪️   ▪️       ▪️   ▪️                                │
│        ▪️   ▪️   ▪️       ▪️                              │
│      이산적인 점들 (유한한 값)                            │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

**왜 디지털로 변환해야 하나?**
- 컴퓨터는 0과 1만 이해함
- 저장, 전송, 처리가 용이
- 복사해도 품질 저하 없음

---

## 1.2 아날로그 → 디지털 변환 (ADC)

### 두 가지 핵심 개념

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│                    ADC (Analog-to-Digital Converter)    │
│                                                         │
│   ┌─────────────┐         ┌─────────────┐              │
│   │  Sampling   │         │ Quantization │              │
│   │  샘플링      │   +     │  양자화       │              │
│   │             │         │              │              │
│   │ "얼마나 자주  │         │ "얼마나 정밀   │              │
│   │  측정할까?"  │         │  하게 표현?"   │              │
│   └─────────────┘         └─────────────┘              │
│         ↓                        ↓                      │
│   Sampling Rate            Bit Depth                    │
│   (Hz)                     (bit)                        │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### Sampling Rate (샘플링 레이트)

> **정의**: 1초에 몇 번 소리를 측정(샘플링)하는가?

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│  원본 아날로그:  ∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿                       │
│                                                         │
│  ─────────────────────────────────────────────────────  │
│                                                         │
│  낮은 샘플링 (4개):    ●       ●       ●       ●        │
│                      듬성듬성 → 정보 손실 많음           │
│                                                         │
│  ─────────────────────────────────────────────────────  │
│                                                         │
│  높은 샘플링 (16개):  ●●●●●●●●●●●●●●●●                   │
│                      촘촘하게 → 원본에 가까움            │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

**실제 사용되는 샘플링 레이트**:

| 샘플링 레이트 | 용도 | 품질 |
|-------------|------|------|
| **8,000 Hz** | 전화 통화 | 최저 (목소리만 알아들을 정도) |
| **16,000 Hz** | 음성 인식 (STT) | 음성에 충분 |
| **44,100 Hz** | CD 음질 | 고품질 음악 |
| **48,000 Hz** | 영상/방송 | 전문가용 |

---

### 🎯 나이퀴스트 정리 (Nyquist Theorem)

> **핵심**: 원본 주파수를 복원하려면 **최소 2배 이상**의 샘플링이 필요하다

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   재현 가능한 최대 주파수 = 샘플링 레이트 ÷ 2            │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   예시:                                                 │
│   • 44,100 Hz 샘플링 → 최대 22,050 Hz 재현 가능         │
│   • 인간 가청 범위: 20 ~ 20,000 Hz                      │
│   • 따라서 CD 음질(44.1kHz)이면 모든 소리 재현 가능!     │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   🎤 음성 인식에서 16kHz를 쓰는 이유:                   │
│   • 인간 목소리의 핵심 주파수: 300 ~ 3,400 Hz           │
│   • 16,000 ÷ 2 = 8,000 Hz까지 커버                     │
│   • 음성 인식에는 충분! (불필요한 고주파 제외)           │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### Bit Depth (비트 깊이)

> **정의**: 각 샘플의 진폭을 몇 단계로 표현하는가?

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   원본 진폭값: 0.7342156...                             │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   4-bit (16단계):     0.75로 반올림                     │
│                       ▓▓▓▓▓▓▓▓▓▓▓▓░░░░                 │
│                       계단 현상 심함                     │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   16-bit (65,536단계): 0.7342로 정밀하게                │
│                        ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓...          │
│                        거의 원본과 동일                  │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

**비트 깊이별 표현력**:

| 비트 깊이 | 표현 가능한 단계 | 용도 |
|----------|----------------|------|
| 8-bit | 256 단계 | 초기 게임, 저품질 |
| **16-bit** | 65,536 단계 | CD, 일반 오디오 |
| 24-bit | 16,777,216 단계 | 전문 녹음 |

---

### 💡 실무 포인트: STT/TTS의 표준 설정

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🎤 대부분의 STT/TTS 시스템 표준:                       │
│                                                         │
│   ┌─────────────────┬─────────────────┐                │
│   │  Sampling Rate  │  Bit Depth      │                │
│   │    16,000 Hz    │    16-bit       │                │
│   └─────────────────┴─────────────────┘                │
│                                                         │
│   → 1초 오디오 = 16,000 × 2 bytes = 32 KB              │
│   → 1분 오디오 = 약 1.9 MB                              │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## 1.3 시간 도메인 vs 주파수 도메인

### 두 가지 관점으로 소리 보기

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│  🕐 시간 도메인 (Time Domain)                           │
│  ─────────────────────────────────                      │
│  "이 순간 진폭이 얼마인가?"                              │
│                                                         │
│       진폭                                              │
│        ↑                                                │
│        │    ∿∿∿∿∿∿∿∿∿∿∿∿                              │
│        │  ∿          ∿                                 │
│        └──────────────────────→ 시간                   │
│                                                         │
│        X축: 시간, Y축: 진폭                              │
│                                                         │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  🎵 주파수 도메인 (Frequency Domain)                    │
│  ─────────────────────────────────                      │
│  "어떤 주파수 성분이 얼마나 있는가?"                     │
│                                                         │
│       세기                                              │
│        ↑    ▓                                          │
│        │    ▓  ▓                                       │
│        │ ▓  ▓  ▓  ░  ░                                 │
│        └──────────────────────→ 주파수                 │
│                                                         │
│        X축: 주파수, Y축: 해당 주파수의 세기              │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### 왜 주파수 분석이 필요한가?

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🗣️ "아" 발음        vs        🗣️ "이" 발음           │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   시간 도메인에서 보면:                                  │
│                                                         │
│   ∿∿∿∿∿∿∿∿∿∿              ∿∿∿∿∿∿∿∿∿∿                 │
│   비슷한 진폭              비슷한 진폭                   │
│                                                         │
│   → 구분하기 어려움! 😕                                  │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   주파수 도메인에서 보면:                                │
│                                                         │
│   ▓ ▓                         ▓     ▓                  │
│   ▓ ▓ ░                       ░ ▓   ▓                  │
│   └──────→                    └──────→                 │
│   낮은 주파수에 에너지 집중     높은 주파수에 에너지 집중  │
│                                                         │
│   → 확연히 다른 패턴! 😊                                 │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

**결론**: AI는 주파수 도메인에서 음성의 특징을 더 잘 파악할 수 있습니다.

---

### Fourier Transform (푸리에 변환)

> **핵심 아이디어**: 모든 복잡한 파형은 여러 주파수의 사인파 합으로 분해할 수 있다

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   복잡한 음성 파형                                       │
│                                                         │
│        ∿∿≋≋∿∿≋∿∿∿≋                                    │
│                                                         │
│              ║ Fourier Transform                        │
│              ▼                                          │
│                                                         │
│   =  ∿∿∿∿∿∿ (100Hz)  ×  0.8                           │
│   +  ≋≋≋≋≋≋ (200Hz)  ×  0.5                           │
│   +  ∾∾∾∾∾∾ (400Hz)  ×  0.3                           │
│   +  ...                                                │
│                                                         │
│   📊 결과: 각 주파수별 "세기(amplitude)" 목록            │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

**비유**: 푸리에 변환은 "음식 레시피 역추적"과 같습니다.
- 완성된 요리(복잡한 파형) → 재료 목록(주파수 성분들)

---

## 1.4 스펙트로그램 (Spectrogram)

### 문제: FFT는 "전체" 주파수만 알려줌

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   "안녕하세요" 전체에 FFT 적용하면?                       │
│                                                         │
│        ▓▓░▓▓░▓░░▓░░░                                   │
│        └────────────→ 주파수                            │
│                                                         │
│   → "안"과 "요"의 주파수가 섞여서 구분 불가! 😕           │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

### 해결: STFT (Short-Time Fourier Transform)

> **아이디어**: 짧은 구간(Frame)으로 나눠서 각각 FFT 수행

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   "안녕하세요" 음성을 시간 구간으로 나눔                  │
│                                                         │
│   ┌────┬────┬────┬────┬────┬────┬────┬────┐           │
│   │ 안 │    │ 녕 │    │ 하 │ 세 │    │ 요 │           │
│   └────┴────┴────┴────┴────┴────┴────┴────┘           │
│     ↓     ↓    ↓    ↓    ↓    ↓    ↓    ↓             │
│    FFT   FFT  FFT  FFT  FFT  FFT  FFT  FFT             │
│     ↓     ↓    ↓    ↓    ↓    ↓    ↓    ↓             │
│   ┌────┬────┬────┬────┬────┬────┬────┬────┐           │
│   │주파│주파│주파│주파│주파│주파│주파│주파│           │
│   │수1 │수2 │수3 │수4 │수5 │수6 │수7 │수8 │           │
│   └────┴────┴────┴────┴────┴────┴────┴────┘           │
│                                                         │
│   → 시간에 따른 주파수 변화를 추적할 수 있음! ✅          │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### 스펙트로그램 읽는 법

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📊 스펙트로그램 (Spectrogram)                         │
│                                                         │
│   주파수                                                │
│   (Hz)  ↑                                               │
│   8000  │ ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░             │
│         │ ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░             │
│   4000  │ ░░▓▓░░▓▓░░▓░░░▓▓░░░░▓▓░░▓▓░░▓▓░             │
│         │ ▓▓▓▓▓▓▓▓▓▓▓░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░             │
│   1000  │ ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓             │
│         │ ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓             │
│      0  └──────────────────────────────────→ 시간       │
│           "안"  "녕"  "하"  "세"    "요"                │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   🎨 색상 의미:                                         │
│   ▓ 진한색 = 에너지 높음 (해당 주파수 성분 강함)         │
│   ░ 연한색 = 에너지 낮음                                │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

**스펙트로그램의 3축**:
- **X축**: 시간 (왼쪽 → 오른쪽)
- **Y축**: 주파수 (아래 = 저음, 위 = 고음)
- **색상**: 에너지 세기 (진할수록 강함)

---

## 1.5 Mel-Spectrogram

### 인간 청각의 비밀

> **발견**: 인간은 주파수를 "비선형적으로" 인식한다

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🎵 물리적 주파수 vs 인간이 느끼는 높낮이               │
│                                                         │
│   100Hz → 200Hz 변화:  "와, 확 높아졌다!" 😲            │
│   8000Hz → 8100Hz 변화: "어? 똑같은데?" 🤔              │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   즉, 저주파에서는 작은 변화도 민감하게 느끼고            │
│       고주파에서는 큰 변화도 잘 느끼지 못함               │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### Mel Scale (멜 스케일)

> **목적**: 인간 청각 특성을 반영한 주파수 스케일

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📏 Hz (선형) vs Mel (로그에 가까움)                    │
│                                                         │
│   Hz:   100   500   1000  2000  4000  8000             │
│          │     │     │     │     │     │               │
│          ▼     ▼     ▼     ▼     ▼     ▼               │
│   Mel:  150   607   1000  1500  2146  2840             │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   시각화:                                               │
│                                                         │
│   Hz 스케일:  |──|──|──|──|──|──|──|──|                │
│               균등 간격                                  │
│                                                         │
│   Mel 스케일: |────|───|──|──|─|─|─|                   │
│               저주파 넓게, 고주파 좁게                    │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### Mel-Spectrogram 생성 과정

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   [원본 오디오]                                         │
│        │                                                │
│        ▼                                                │
│   ┌─────────────┐                                       │
│   │    STFT     │  → 시간별 주파수 분석                 │
│   └─────────────┘                                       │
│        │                                                │
│        ▼                                                │
│   ┌─────────────┐                                       │
│   │  Magnitude  │  → 크기(에너지)만 추출               │
│   └─────────────┘                                       │
│        │                                                │
│        ▼                                                │
│   ┌─────────────────────┐                               │
│   │  Mel Filter Bank    │  → 인간 청각 특성 적용        │
│   │  (삼각 필터 뭉치)    │                              │
│   └─────────────────────┘                               │
│        │                                                │
│        ▼                                                │
│   ┌─────────────┐                                       │
│   │     Log     │  → 로그 스케일 (dB)                  │
│   └─────────────┘                                       │
│        │                                                │
│        ▼                                                │
│   [Mel-Spectrogram] 완성!                               │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### Mel Filter Bank 시각화

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📐 Mel Filter Bank (삼각 필터들)                      │
│                                                         │
│   세기                                                  │
│    ↑                                                    │
│    │    /\      /\     /\    /\   /\  /\ /\/\          │
│    │   /  \    /  \   /  \  /  \ /  \/  \              │
│    │  /    \  /    \ /    \/    \                      │
│    │ /      \/      \                                  │
│    └──────────────────────────────────────→ 주파수     │
│       0    500   1000  2000  4000   8000 Hz            │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   💡 특징:                                              │
│   • 저주파: 필터가 좁고 촘촘 (세밀하게 분석)             │
│   • 고주파: 필터가 넓고 듬성 (뭉뚱그려 분석)             │
│   • 인간이 중요하게 느끼는 대역에 집중!                  │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### 왜 Mel-Spectrogram인가?

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📊 일반 Spectrogram vs Mel-Spectrogram 비교           │
│                                                         │
│   ┌──────────────────┬──────────────────┐              │
│   │ 일반 Spectrogram │ Mel-Spectrogram  │              │
│   ├──────────────────┼──────────────────┤              │
│   │ 차원: ~1000개    │ 차원: 40~128개   │ ← 효율적     │
│   │ 선형 주파수      │ 청각 특성 반영   │ ← 자연스러움 │
│   │ 노이즈에 민감    │ 노이즈에 강건    │ ← 실용적     │
│   └──────────────────┴──────────────────┘              │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   ✅ Mel-Spectrogram은 STT/TTS의 "표준 입력"            │
│                                                         │
│   • Whisper, Wav2Vec → Mel-Spectrogram 사용            │
│   • Tacotron, VITS → Mel-Spectrogram 생성              │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## 📸 [시각화 자료 슬라이드]

### 추천 시각화 자료 목록

| 자료 | 설명 | 활용 |
|------|------|------|
| **파형 vs 스펙트로그램** | 같은 음성의 두 가지 표현 비교 | 도메인 차이 설명 |
| **샘플링 레이트 비교** | 44.1kHz vs 8kHz 파형 비교 | 나이퀴스트 정리 |
| **모음별 스펙트로그램** | 아/이/우 발음의 스펙트로그램 | 주파수 패턴 차이 |
| **Mel Filter Bank** | 삼각 필터 배치 그림 | Mel 스케일 이해 |
| **"안녕하세요" 스펙트로그램** | 실제 한국어 음성 예시 | 실습 시 활용 |

---

## 🎯 Chapter 1 핵심 요약

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📌 기억해야 할 것들                                    │
│                                                         │
│   1. 소리 → 디지털: Sampling Rate + Bit Depth           │
│                                                         │
│   2. 나이퀴스트 정리: 샘플링은 최대 주파수의 2배 이상     │
│                                                         │
│   3. STT 표준: 16kHz, 16-bit                           │
│                                                         │
│   4. 푸리에 변환: 시간 도메인 → 주파수 도메인            │
│                                                         │
│   5. 스펙트로그램: 시간 + 주파수 + 에너지 3차원 표현     │
│                                                         │
│   6. Mel-Spectrogram: 인간 청각 반영, AI 표준 입력      │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

# Chapter 2. 불규칙한 소리를 규칙적인 텍스트로 (STT 심화)

> **핵심 질문**: 길이가 제각각인 음성을 어떻게 정확한 텍스트로 변환할까?

---

## 2.1 STT의 근본적 난제: Alignment 문제

### 음성과 텍스트의 길이 불일치

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🗣️ 같은 문장, 다른 속도                               │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   빠르게: "안녕하세요" (0.8초)                           │
│           ████████                                      │
│           → 80 프레임                                   │
│                                                         │
│   느리게: "안녕하세요" (1.5초)                           │
│           ████████████████                              │
│           → 150 프레임                                  │
│                                                         │
│   텍스트: "안녕하세요"                                   │
│           → 5글자 (항상 고정!)                          │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   ❓ 어떤 프레임이 어떤 글자에 대응하는지 어떻게 알지?    │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### Alignment 문제 시각화

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📊 프레임-텍스트 대응 관계                             │
│                                                         │
│   프레임:  [1][2][3][4][5][6][7][8][9][10][11][12]...   │
│             ?  ?  ?  ?  ?  ?  ?  ?  ?  ?   ?   ?        │
│   텍스트:  [안]    [녕]    [하]   [세]    [요]          │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   😰 문제점:                                            │
│   • 경계가 어디인지 모름 (프레임 3이 "안"? "녕"?)        │
│   • 같은 글자도 사람마다 길이가 다름                     │
│   • 묵음 구간은 어떻게 처리?                            │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### 전통적 방식의 한계

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🏛️ 과거 방식 (HMM-GMM 시대, ~2012)                    │
│                                                         │
│   [음성] → 강제 정렬(Forced Alignment) → [텍스트]       │
│                ↑                                        │
│           수작업으로 경계 표시 필요!                     │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   😫 문제:                                              │
│   • 데이터마다 일일이 "여기서 '안' 끝, 여기서 '녕' 시작" │
│   • 비용과 시간이 막대함                                │
│   • 확장성 없음                                         │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   🎯 딥러닝의 목표:                                     │
│   "정렬 정보 없이도 학습할 수 있게 하자!"                │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## 2.2 CTC (Connectionist Temporal Classification)

### CTC의 핵심 아이디어

> **"정렬을 몰라도 괜찮아! 가능한 모든 정렬의 확률을 합치자"**

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🎯 CTC의 마법: Blank 토큰 (ε)                         │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   입력 프레임:  [1] [2] [3] [4] [5] [6] [7]             │
│                 ↓   ↓   ↓   ↓   ↓   ↓   ↓              │
│   CTC 출력:     ε  안  안   ε  녕   ε  녕               │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   💡 ε (Blank)의 역할:                                  │
│   • "아직 다음 글자로 안 넘어갔어요" 표시                │
│   • 글자 사이의 경계 역할                               │
│   • 묵음 구간 표현                                      │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### CTC 디코딩 규칙

> **두 단계로 최종 텍스트 도출**

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📝 CTC 디코딩 과정                                    │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   Step 1: 연속된 같은 글자 → 하나로 병합                 │
│   ═══════════════════════════════════════════════════   │
│                                                         │
│   [ε][안][안][ε][녕][ε][녕]                              │
│          ↓↓                ↓↓                           │
│   [ε][안   ][ε][녕][ε][녕]                               │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   Step 2: Blank(ε) 제거                                 │
│   ═══════════════════════════════════════════════════   │
│                                                         │
│   [ε][안][ε][녕][ε][녕]                                  │
│    ✗      ✗      ✗                                      │
│      [안]   [녕]   [녕]                                  │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   ✅ 최종 결과: "안녕"                                   │
│                                                         │
│   ⚠️ 잠깐! "녕녕"이 아니라 "녕"인 이유:                  │
│      Step 1에서 연속 "녕녕"이 아님 (사이에 ε 있음)       │
│      → 서로 다른 "녕"으로 인식                          │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### CTC 디코딩 퀴즈

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🧩 퀴즈: 다음 CTC 출력의 최종 결과는?                  │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│                                                         │
│   Q1: [ε][가][가][ε][ε][나][다][다][다][ε]               │
│                                                         │
│       정답: "가나다"                                     │
│       풀이: 가가→가, 다다다→다, ε 제거                   │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   Q2: [ε][ε][아][ε][아][ε][ε]                            │
│                                                         │
│       정답: "아아"                                       │
│       풀이: 사이에 ε가 있으므로 서로 다른 "아"           │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   Q3: [바][바][바][나][나][나]                           │
│                                                         │
│       정답: "바나"                                       │
│       풀이: 연속 같은 글자 병합 (ε 없어도 동작)          │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### CTC의 장단점

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   ✅ CTC의 장점                                         │
│                                                         │
│   • 정렬 레이블 없이 학습 가능 (End-to-End)              │
│   • 구현이 비교적 단순                                   │
│   • 학습이 안정적                                        │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   ❌ CTC의 단점                                         │
│                                                         │
│   • 조건부 독립 가정: 각 프레임을 독립적으로 예측        │
│     → 앞뒤 문맥을 충분히 활용 못함                      │
│                                                         │
│   • 출력 길이 ≤ 입력 길이 제약                          │
│     → 음성보다 긴 텍스트 생성 불가                      │
│                                                         │
│   • 언어 모델 통합이 어려움                             │
│     → 문법적으로 자연스러운 문장 생성에 한계             │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## 2.3 Attention 메커니즘

### Attention의 핵심 아이디어

> **"출력을 생성할 때, 입력의 어느 부분에 집중할지 스스로 결정"**

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🎯 Attention 작동 원리                                │
│                                                         │
│   입력 (음성 프레임):                                    │
│   [프레임1] [프레임2] [프레임3] [프레임4] [프레임5]      │
│       ↓         ↓         ↓         ↓         ↓        │
│     0.05      0.70      0.15      0.05      0.05       │
│                 ↑                                       │
│           가장 집중!                                    │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   "안" 글자를 생성할 때:                                 │
│   → 음성 초반 프레임에 높은 가중치 (집중)                │
│                                                         │
│   "요" 글자를 생성할 때:                                 │
│   → 음성 후반 프레임에 높은 가중치 (집중)                │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### Attention 히트맵 (시각화)

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📊 Attention 히트맵 - "안녕하세요" 인식 예시           │
│                                                         │
│              ← 입력 (음성 프레임, 시간) →               │
│          [1] [2] [3] [4] [5] [6] [7] [8] [9] [10]       │
│        ┌─────────────────────────────────────┐          │
│   출   │ ■  ■  ░  ░  ░  ░  ░  ░  ░  ░ │ "안"        │
│   력   │ ░  ░  ■  ■  ░  ░  ░  ░  ░  ░ │ "녕"        │
│   텍   │ ░  ░  ░  ░  ■  ■  ░  ░  ░  ░ │ "하"        │
│   스   │ ░  ░  ░  ░  ░  ░  ■  ■  ░  ░ │ "세"        │
│   트   │ ░  ░  ░  ░  ░  ░  ░  ░  ■  ■ │ "요"        │
│        └─────────────────────────────────────┘          │
│                                                         │
│   ■ = 높은 attention (집중)                             │
│   ░ = 낮은 attention                                    │
│                                                         │
│   💡 대각선 패턴: 음성이 순차적으로 텍스트와 대응        │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### Attention vs CTC 비교

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📊 CTC vs Attention 비교                              │
│                                                         │
│   ┌────────────────┬─────────────────┐                 │
│   │      CTC       │    Attention    │                 │
│   ├────────────────┼─────────────────┤                 │
│   │ 프레임별 독립   │ 문맥 고려       │                 │
│   │ 예측            │                 │                 │
│   ├────────────────┼─────────────────┤                 │
│   │ 출력 ≤ 입력    │ 출력 길이 자유  │                 │
│   ├────────────────┼─────────────────┤                 │
│   │ 학습 안정적    │ 학습 어려울 수  │                 │
│   │                │ 있음            │                 │
│   ├────────────────┼─────────────────┤                 │
│   │ 실시간 적합    │ 긴 문장에 강함  │                 │
│   └────────────────┴─────────────────┘                 │
│                                                         │
│   💡 현대 모델: 둘을 결합해서 사용하기도 함!             │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## 2.4 Transformer 기반 모델

### Self-Attention의 혁신

> **"입력 시퀀스 내부의 관계도 학습한다"**

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🔄 Self-Attention 작동 방식                           │
│                                                         │
│   입력: "나는 학교에 간다"                               │
│                                                         │
│         나는  ←──────────────────→  학교에              │
│           ↕                           ↕                 │
│         간다  ←──────────────────→  (관계 학습)         │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   💡 효과:                                              │
│   • "나는"이 "간다"와 문법적으로 연결됨을 학습           │
│   • "학교에"가 장소임을 문맥에서 파악                    │
│   • 멀리 떨어진 토큰 간 관계도 직접 연결                 │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### Transformer Encoder 구조

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🏗️ Transformer Encoder (STT용)                        │
│                                                         │
│   [Mel-Spectrogram 입력]                                │
│            ↓                                            │
│   ┌─────────────────────┐                               │
│   │ Input Embedding     │  음향 특징 → 벡터 변환        │
│   │ + Positional Enc.   │  위치 정보 추가              │
│   └──────────┬──────────┘                               │
│              ↓                                          │
│   ╔═══════════════════════╗                             │
│   ║  Multi-Head           ║                             │
│   ║  Self-Attention       ║  여러 관점에서 관계 분석    │
│   ╠═══════════════════════╣                             │
│   ║  Add & Normalize      ║  안정화                     │
│   ╠═══════════════════════╣                             │
│   ║  Feed Forward         ║  비선형 변환               │
│   ╠═══════════════════════╣                             │
│   ║  Add & Normalize      ║  안정화                     │
│   ╚═══════════════════════╝                             │
│              ↓                                          │
│         (N번 반복)                                       │
│              ↓                                          │
│   [인코딩된 음성 표현]                                   │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### 현대 STT 모델 흐름

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📅 STT 모델의 발전                                    │
│                                                         │
│   2012 이전    2015~2018     2019~2020     2022~현재   │
│   ─────────────────────────────────────────────────────│
│                                                         │
│   HMM-GMM  →  RNN+CTC  →  Transformer  →  대규모 사전  │
│                            +Attention     학습 모델    │
│                                                         │
│   DeepSpeech   LAS         Wav2Vec 2.0   Whisper      │
│                            Conformer                   │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   🎯 Whisper (OpenAI, 2022):                           │
│   • 68만 시간 다국어 데이터 학습                        │
│   • Encoder-Decoder Transformer                        │
│   • 별도 설정 없이 다국어 인식                          │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## 2.5 Decoding 전략

### Greedy Search (탐욕적 탐색)

> **"매 순간 가장 확률 높은 것만 선택"**

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🎯 Greedy Search 동작                                 │
│                                                         │
│   Step 1:  안(0.7)  앙(0.2)  언(0.1)  → "안" 선택       │
│                                                         │
│   Step 2:  녕(0.8)  년(0.1)  녀(0.1)  → "녕" 선택       │
│                                                         │
│   Step 3:  하(0.9)  ...              → "하" 선택       │
│                                                         │
│   ...                                                   │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   ✅ 장점: 빠름! (한 방향으로만 진행)                    │
│   ❌ 단점: 최적해 보장 못함 (근시안적 선택)              │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### Beam Search (빔 탐색)

> **"상위 K개 후보를 유지하며 탐색"**

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🌳 Beam Search (Beam Width = 3)                       │
│                                                         │
│   Step 1:                                               │
│                     [시작]                              │
│                    /  |  \                              │
│                   /   |   \                             │
│               "안"  "앙"  "언"                          │
│               0.7   0.2   0.1                           │
│                                                         │
│   Step 2:      (상위 3개만 확장)                        │
│                                                         │
│            "안녕"   "안년"   "앙녕"                      │
│            0.56    0.07    0.12                         │
│                                                         │
│   Step 3:      (다시 상위 3개만 유지)                   │
│                                                         │
│          "안녕하"  "안녕허"  "앙녕하"                    │
│           0.50     0.04     0.10                        │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   ✅ 장점: Greedy보다 좋은 결과                         │
│   ❌ 단점: K배 느림 (하지만 감당 가능)                   │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### Greedy vs Beam Search 비교

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📊 언제 무엇을 쓸까?                                   │
│                                                         │
│   ┌─────────────────┬─────────────────┐                │
│   │  Greedy Search  │  Beam Search    │                │
│   ├─────────────────┼─────────────────┤                │
│   │ 속도: ⚡ 매우 빠름 │ 속도: 🐢 느림    │                │
│   │ 품질: ⭐⭐⭐      │ 품질: ⭐⭐⭐⭐⭐ │                │
│   │                 │                 │                │
│   │ 📱 실시간 자막   │ 📄 회의록 작성   │                │
│   │ 🎮 음성 명령     │ 📚 오디오북 변환 │                │
│   │ 💬 실시간 통화   │ 🎬 영상 자막     │                │
│   └─────────────────┴─────────────────┘                │
│                                                         │
│   💡 실무 Tip:                                          │
│   • 실시간 필요 → Greedy                               │
│   • 정확도 중요 → Beam Search (k=4~10)                 │
│   • 타협점 → Beam Search (k=2~3)                       │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## 📸 [시각화 자료 슬라이드]

### 추천 시각화 자료 목록

| 자료 | 설명 | 활용 |
|------|------|------|
| **CTC 디코딩 과정 애니메이션** | ε 병합/제거 단계별 | CTC 이해 |
| **Attention 히트맵** | 대각선 패턴 강조 | Attention 직관적 이해 |
| **Transformer 구조도** | 블록 다이어그램 | 아키텍처 설명 |
| **Beam Search 트리** | 확률과 함께 분기 시각화 | 디코딩 전략 비교 |
| **STT 모델 발전 타임라인** | 연도별 주요 모델 | 역사적 맥락 |

---

## 🎯 Chapter 2 핵심 요약

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📌 기억해야 할 것들                                    │
│                                                         │
│   1. Alignment 문제: 음성 길이 ≠ 텍스트 길이            │
│                                                         │
│   2. CTC: Blank(ε)로 정렬 없이 학습                     │
│      - 연속 중복 제거 → Blank 제거                      │
│                                                         │
│   3. Attention: 입력의 어디에 집중할지 학습             │
│      - 히트맵으로 시각화 가능                           │
│                                                         │
│   4. Transformer: Self-Attention으로 문맥 파악          │
│      - 현대 STT의 표준 아키텍처                         │
│                                                         │
│   5. Decoding: Greedy (빠름) vs Beam (정확)             │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

# Chapter 3. 텍스트에 생명(운율)을 불어넣기 (TTS 심화)

> **핵심 질문**: 글자에 불과한 텍스트를 어떻게 자연스러운 음성으로 만들까?

---

## 3.1 TTS의 핵심 2단계 구조

### 왜 한 번에 못 만들까?

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🤔 직접 변환의 어려움                                  │
│                                                         │
│   입력: "안녕"                                          │
│         2글자                                           │
│                                                         │
│   출력: [0.1, -0.2, 0.3, 0.1, -0.1, ...]               │
│         16,000 숫자/초 × 0.5초 = 8,000개!               │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   😱 문제:                                              │
│   • 입출력 차원이 너무 다름 (2 vs 8000)                 │
│   • 텍스트에는 억양, 속도 정보가 없음                    │
│   • 같은 글자도 상황에 따라 다르게 발음                  │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### 2단계 구조의 해결책

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🎯 TTS의 2단계 파이프라인                             │
│                                                         │
│   [텍스트]                                              │
│      │                                                  │
│      ▼                                                  │
│   ┌─────────────────────────────────────────┐          │
│   │         Acoustic Model (음향 모델)       │          │
│   │                                         │          │
│   │  "어떤 주파수로, 얼마나 길게,           │          │
│   │   어떤 억양으로 발음할지 결정"           │          │
│   └─────────────────────────────────────────┘          │
│      │                                                  │
│      ▼                                                  │
│   [Mel-Spectrogram] ← 중간 표현                        │
│      │                                                  │
│      ▼                                                  │
│   ┌─────────────────────────────────────────┐          │
│   │            Vocoder (보코더)              │          │
│   │                                         │          │
│   │  "Mel-Spectrogram을 실제 파형으로 변환" │          │
│   └─────────────────────────────────────────┘          │
│      │                                                  │
│      ▼                                                  │
│   [오디오 파형]                                         │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### 각 단계의 역할

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📊 역할 분담                                          │
│                                                         │
│   ┌───────────────────────────────────────────────┐    │
│   │            Acoustic Model                     │    │
│   ├───────────────────────────────────────────────┤    │
│   │ • 텍스트 → 음향 특성 변환                     │    │
│   │ • 발음 결정 (G2P 포함)                        │    │
│   │ • 운율 결정 (억양, 강세, 속도)                │    │
│   │ • Duration 결정 (각 음소 길이)                │    │
│   │                                               │    │
│   │ 출력: Mel-Spectrogram (80차원 × 시간)        │    │
│   └───────────────────────────────────────────────┘    │
│                          ↓                              │
│   ┌───────────────────────────────────────────────┐    │
│   │               Vocoder                         │    │
│   ├───────────────────────────────────────────────┤    │
│   │ • Mel-Spectrogram → 오디오 파형               │    │
│   │ • 미세한 음향 디테일 생성                     │    │
│   │ • 자연스러운 음색 복원                        │    │
│   │                                               │    │
│   │ 출력: 1차원 오디오 (16,000 샘플/초)           │    │
│   └───────────────────────────────────────────────┘    │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### 대표적인 TTS 모델

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🏛️ TTS 모델 분류                                      │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   2단계 모델 (Acoustic Model + Vocoder)                 │
│   ═══════════════════════════════════════════════════   │
│                                                         │
│   • Tacotron 2 + WaveNet (Google, 2018)                │
│     - Attention 기반, 고품질이지만 느림                 │
│                                                         │
│   • FastSpeech 2 + HiFi-GAN (2020)                     │
│     - 비자기회귀, 빠르고 안정적                         │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   End-to-End 모델 (통합)                                │
│   ═══════════════════════════════════════════════════   │
│                                                         │
│   • VITS (2021)                                        │
│     - Acoustic + Vocoder 통합                          │
│     - 고품질 + 빠른 속도                               │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## 3.2 텍스트 전처리

### Text Normalization (텍스트 정규화)

> **"읽을 수 없는 형태를 읽을 수 있는 형태로"**

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🔄 텍스트 정규화가 필요한 경우                         │
│                                                         │
│   ┌───────────────────┬───────────────────────────┐    │
│   │ 원본              │ 정규화 후                  │    │
│   ├───────────────────┼───────────────────────────┤    │
│   │ 2024년            │ 이천이십사년              │    │
│   │ 1월 1일           │ 일월 일일                 │    │
│   │ ₩50,000           │ 오만원                    │    │
│   │ 3:30 PM           │ 오후 세시 삼십분          │    │
│   │ Dr. Kim           │ 닥터 김 (또는 김 박사)    │    │
│   │ 50%               │ 오십 퍼센트               │    │
│   │ &                 │ 앤드 (또는 그리고)        │    │
│   │ 02-1234-5678      │ 공이 일이삼사 오육칠팔    │    │
│   └───────────────────┴───────────────────────────┘    │
│                                                         │
│   💡 정규화 안 하면?                                    │
│   → TTS가 "₩50,000"을 그대로 발음하려고 시도            │
│   → 이상한 소리 또는 오류 발생                          │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### G2P (Grapheme to Phoneme)

> **"문자를 실제 발음으로 변환"**

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🗣️ 왜 G2P가 필요한가?                                 │
│                                                         │
│   한국어는 "적힌 대로" 읽지 않는 경우가 많다!            │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   ┌──────────┬───────────┬───────────────────────┐     │
│   │ 문자     │ 실제 발음  │ 음운 규칙             │     │
│   ├──────────┼───────────┼───────────────────────┤     │
│   │ 같이     │ 가치      │ 구개음화              │     │
│   │ 학교     │ 학꾜      │ 경음화                │     │
│   │ 국민     │ 궁민      │ 비음화                │     │
│   │ 음악을   │ 으마글    │ 연음 + 비음화         │     │
│   │ 좋아요   │ 조아요    │ ㅎ 탈락               │     │
│   │ 맛있다   │ 마싣따    │ 연음 + 경음화         │     │
│   │ 신라     │ 실라      │ 유음화                │     │
│   └──────────┴───────────┴───────────────────────┘     │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### 한국어 주요 음운 규칙

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📚 한국어 음운 규칙 (G2P가 처리해야 할 것들)           │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   1. 연음 (Liaison)                                     │
│   ═══════════════════════════════════════════════════   │
│   받침 + 모음 → 받침이 뒤로 이동                        │
│   예: 음악을 → 으마글                                   │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   2. 비음화 (Nasalization)                              │
│   ═══════════════════════════════════════════════════   │
│   ㄱ,ㄷ,ㅂ + ㄴ,ㅁ → ㅇ,ㄴ,ㅁ + ㄴ,ㅁ                   │
│   예: 국민 → 궁민, 갑니다 → 감니다                      │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   3. 경음화 (Fortition)                                 │
│   ═══════════════════════════════════════════════════   │
│   받침 + ㄱ,ㄷ,ㅂ,ㅅ,ㅈ → 받침 + ㄲ,ㄸ,ㅃ,ㅆ,ㅉ         │
│   예: 학교 → 학꾜, 식당 → 식땅                          │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   4. 구개음화 (Palatalization)                          │
│   ═══════════════════════════════════════════════════   │
│   ㄷ,ㅌ + 이 → ㅈ,ㅊ + 이                               │
│   예: 같이 → 가치, 굳이 → 구지                          │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   5. ㅎ 탈락                                            │
│   ═══════════════════════════════════════════════════   │
│   ㅎ + 모음 → ㅎ 사라짐                                 │
│   예: 좋아 → 조아, 놓아 → 노아                          │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### TTS 전처리 전체 파이프라인

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🔄 텍스트 전처리 파이프라인                            │
│                                                         │
│   [원본 텍스트]                                         │
│   "2024년 1월, 같이 학교에 갑니다."                     │
│            │                                            │
│            ▼                                            │
│   ┌─────────────────────────┐                           │
│   │   Text Normalization    │                           │
│   └─────────────────────────┘                           │
│   "이천이십사년 일월, 같이 학교에 갑니다."               │
│            │                                            │
│            ▼                                            │
│   ┌─────────────────────────┐                           │
│   │          G2P            │                           │
│   └─────────────────────────┘                           │
│   "이천이십사년 이뤌, 가치 학꾜에 감니다."               │
│            │                                            │
│            ▼                                            │
│   ┌─────────────────────────┐                           │
│   │   Phoneme Embedding     │                           │
│   └─────────────────────────┘                           │
│   [벡터 시퀀스]                                         │
│            │                                            │
│            ▼                                            │
│   [Acoustic Model로 전달]                               │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## 3.3 Neural Vocoder의 원리

### Vocoder의 역할

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🎵 Vocoder가 하는 일                                  │
│                                                         │
│   입력: Mel-Spectrogram                                │
│   ┌─────────────────────────────────────────┐          │
│   │ ▓▓░░▓▓▓░░▓░░░▓▓▓░░▓▓▓░░▓▓▓░░           │          │
│   │ (80차원 × 시간 프레임)                   │          │
│   └─────────────────────────────────────────┘          │
│                    │                                    │
│                    ▼                                    │
│   출력: 오디오 파형                                     │
│   ┌─────────────────────────────────────────┐          │
│   │ ∿∿∿~~~∿∿∿~~~∿∿∿~~~∿∿∿~~~∿∿∿~~~        │          │
│   │ (16,000 샘플/초)                         │          │
│   └─────────────────────────────────────────┘          │
│                                                         │
│   💡 핵심 과제: "어떻게 80개 숫자를 수만 개로 확장?"     │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### Griffin-Lim vs Neural Vocoder

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📊 전통적 방식 vs 딥러닝 방식                          │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   Griffin-Lim (전통적)                                  │
│   ═══════════════════════════════════════════════════   │
│                                                         │
│   • 수학적 알고리즘으로 위상(phase) 복원                 │
│   • 반복 계산 (60~100회)                                │
│   • 빠르지만 음질이 "기계적"                            │
│   • 금속성, 버저 같은 느낌                              │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   Neural Vocoder (딥러닝)                               │
│   ═══════════════════════════════════════════════════   │
│                                                         │
│   • 신경망이 자연스러운 파형을 학습                      │
│   • 실제 음성 데이터에서 패턴 학습                       │
│   • 훨씬 자연스럽고 사람 같은 음성                       │
│   • 계산량이 많았으나 최근 해결됨                        │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### HiFi-GAN의 혁신

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🚀 HiFi-GAN (2020) - 실시간 고품질 Vocoder            │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   핵심 아이디어: GAN (적대적 생성 신경망)                │
│   ═══════════════════════════════════════════════════   │
│                                                         │
│                  진짜 같은 가짜를 만들자!                │
│                                                         │
│   ┌──────────────┐          ┌──────────────┐           │
│   │  Generator   │ ──생성──▶│Discriminator │           │
│   │  (생성자)    │          │  (판별자)    │           │
│   └──────────────┘          └──────────────┘           │
│          │                         │                    │
│          │     "진짜 vs 가짜"      │                    │
│          │◀────────────────────────│                    │
│          │    피드백으로 개선       │                    │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   💡 결과:                                              │
│   • 실시간보다 빠른 속도 (GPU 기준)                     │
│   • 사람과 구분 어려운 음질                             │
│   • 현재 TTS의 표준 Vocoder                            │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### Vocoder 발전 타임라인

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📅 Vocoder 발전사                                     │
│                                                         │
│   2016        2018         2019         2020           │
│   ─────────────────────────────────────────────────    │
│                                                         │
│   WaveNet  →  WaveGlow  →  MelGAN  →  HiFi-GAN        │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   WaveNet (2016, DeepMind)                             │
│   • 혁명적 품질, 하지만 극도로 느림                     │
│   • 1초 음성 생성에 몇 분 소요                          │
│                                                         │
│   WaveGlow (2018, NVIDIA)                              │
│   • Flow 기반, 병렬 처리 가능                          │
│   • 실시간 근접, 하지만 모델 큼                        │
│                                                         │
│   HiFi-GAN (2020)                                      │
│   • GAN 기반, 가볍고 빠름                              │
│   • 실시간 + 고품질 달성 ✅                            │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## 📸 [시각화 자료 슬라이드]

### 추천 시각화 자료 목록

| 자료 | 설명 | 활용 |
|------|------|------|
| **TTS 2단계 구조도** | Acoustic Model → Vocoder 흐름 | 전체 구조 이해 |
| **Text Normalization 예시** | 변환 전/후 비교 표 | 전처리 필요성 |
| **G2P 변환 예시** | 한국어 음운 규칙 적용 | 발음 변환 이해 |
| **Griffin-Lim vs HiFi-GAN** | 파형 비교 + 오디오 샘플 | 품질 차이 체감 |
| **GAN 구조 다이어그램** | Generator-Discriminator 관계 | HiFi-GAN 원리 |

---

## 🎯 Chapter 3 핵심 요약

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📌 기억해야 할 것들                                    │
│                                                         │
│   1. TTS = Acoustic Model + Vocoder (2단계)             │
│                                                         │
│   2. Text Normalization: 숫자, 기호 등을 읽을 수 있게   │
│                                                         │
│   3. G2P: 문자를 실제 발음으로 변환                     │
│      - 한국어는 음운 규칙이 복잡함                      │
│                                                         │
│   4. Vocoder: Mel-Spectrogram → 오디오 파형             │
│      - HiFi-GAN: 현재 표준, 실시간 고품질               │
│                                                         │
│   5. 전처리가 TTS 품질의 핵심!                          │
│      - 잘못된 발음 = 부자연스러운 음성                  │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

# Chapter 4. 개발자가 알아야 할 평가지표와 이슈

> **핵심 질문**: STT/TTS 시스템을 어떻게 평가하고, 실무에서 어떤 문제를 해결해야 할까?

---

## 4.1 STT 성능 평가 지표

### WER (Word Error Rate)

> **"단어 단위로 얼마나 틀렸는가?"**

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📐 WER 계산 공식                                      │
│                                                         │
│              S + D + I                                  │
│   WER = ─────────────── × 100%                         │
│                N                                        │
│                                                         │
│   S = Substitution (대체된 단어 수)                     │
│   D = Deletion (삭제된 단어 수)                         │
│   I = Insertion (삽입된 단어 수)                        │
│   N = 정답의 총 단어 수                                 │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### WER 계산 예시

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📝 예시                                               │
│                                                         │
│   정답: "오늘 날씨가 정말 좋습니다"                      │
│   예측: "오늘 날씨 정말 좋습니다요"                      │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   비교:                                                 │
│   정답: 오늘 / 날씨가 / 정말 / 좋습니다                 │
│   예측: 오늘 / 날씨   / 정말 / 좋습니다요               │
│           ✓      ✗      ✓       ✗                      │
│                  │              │                       │
│           "가" 삭제(D)   "요" 삽입(I)                   │
│                                                         │
│   계산:                                                 │
│   S = 0 (대체 없음)                                     │
│   D = 1 ("가" 삭제)                                     │
│   I = 1 ("요" 삽입)                                     │
│   N = 4 (정답 단어 수)                                  │
│                                                         │
│   WER = (0 + 1 + 1) / 4 = 50%                          │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### CER (Character Error Rate)

> **"문자 단위로 얼마나 틀렸는가?"**

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🆚 WER vs CER - 한국어에서의 차이                     │
│                                                         │
│   정답: "학교에"                                        │
│   예측: "학교가"                                        │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   WER 관점:                                             │
│   • 단어 1개 틀림                                       │
│   • WER = 1/1 = 100% 😱                                │
│                                                         │
│   CER 관점:                                             │
│   • 문자 1개 틀림 (에→가)                              │
│   • CER = 1/3 = 33% 😊                                 │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   💡 한국어는 조사가 많아서 CER이 더 공정한 평가!        │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### 언어별 권장 지표

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🌍 언어별 권장 평가 지표                               │
│                                                         │
│   ┌──────────────┬──────────────┬──────────────────┐   │
│   │ 언어         │ 권장 지표     │ 이유             │   │
│   ├──────────────┼──────────────┼──────────────────┤   │
│   │ 영어         │ WER          │ 띄어쓰기 명확    │   │
│   │ 한국어       │ CER          │ 조사/어미 변화   │   │
│   │ 중국어       │ CER          │ 띄어쓰기 없음    │   │
│   │ 일본어       │ CER          │ 혼합 문자 체계   │   │
│   └──────────────┴──────────────┴──────────────────┘   │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   📊 실무에서는 보통 둘 다 측정!                        │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## 4.2 TTS 정성 평가 지표

### MOS (Mean Opinion Score)

> **"사람이 직접 듣고 점수를 매기는 방식"**

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   ⭐ MOS 점수 기준                                      │
│                                                         │
│   ┌───────┬─────────────┬────────────────────────────┐ │
│   │ 점수  │ 등급        │ 설명                       │ │
│   ├───────┼─────────────┼────────────────────────────┤ │
│   │  5    │ Excellent   │ 실제 사람과 구분 불가      │ │
│   │  4    │ Good        │ 자연스럽지만 약간 인공적   │ │
│   │  3    │ Fair        │ 이해 가능하나 기계적       │ │
│   │  2    │ Poor        │ 이해하기 어려움            │ │
│   │  1    │ Bad         │ 이해 불가                  │ │
│   └───────┴─────────────┴────────────────────────────┘ │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   💡 현대 TTS 모델 (VITS, HiFi-GAN 등):                 │
│      MOS 4.0 이상 달성 → 사람에 근접!                   │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### MOS 측정 방법

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📋 MOS 측정 프로토콜                                   │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   1. 평가자 모집                                        │
│   ═══════════════════════════════════════════════════   │
│   • 최소 20명 이상 권장                                 │
│   • 원어민 또는 해당 언어 능숙자                        │
│   • 청력 문제 없는 사람                                 │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   2. 샘플 준비                                          │
│   ═══════════════════════════════════════════════════   │
│   • 다양한 문장 (짧은/긴, 질문/평서문)                  │
│   • 무작위 순서로 제시                                  │
│   • 참조용 실제 사람 음성 포함                          │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   3. 평가 및 분석                                       │
│   ═══════════════════════════════════════════════════   │
│   • 각 샘플에 1~5점 부여                               │
│   • 평균 및 95% 신뢰구간 계산                          │
│   • 이상치(outlier) 제거 고려                          │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### TTS 객관적 평가 지표

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📊 MOS 외 평가 지표들                                 │
│                                                         │
│   ┌────────────────┬────────────────────────────────┐  │
│   │ 지표           │ 설명                           │  │
│   ├────────────────┼────────────────────────────────┤  │
│   │ MCD            │ Mel Cepstral Distortion        │  │
│   │                │ (낮을수록 좋음)                 │  │
│   │                │ 생성 음성 vs 실제 음성 거리    │  │
│   ├────────────────┼────────────────────────────────┤  │
│   │ F0 RMSE        │ 음높이(피치) 오차               │  │
│   │                │ (낮을수록 좋음)                 │  │
│   ├────────────────┼────────────────────────────────┤  │
│   │ Duration Error │ 발화 길이 오차                 │  │
│   │                │ 예상 길이 vs 실제 길이         │  │
│   └────────────────┴────────────────────────────────┘  │
│                                                         │
│   ⚠️ 하지만...                                          │
│   객관적 지표가 좋아도 사람이 듣기에 어색할 수 있음!    │
│   → MOS가 여전히 가장 중요한 지표                       │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## 4.3 실무 고려사항

### 실시간 처리 (Latency)

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   ⏱️ Latency란?                                         │
│                                                         │
│   [사용자 말 시작] ──────────────────▶ [결과 표시]      │
│                    │◀──── Latency ────▶│               │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   📊 Latency 구성 요소                                  │
│                                                         │
│   Total Latency =                                       │
│       Audio Capture (녹음)                              │
│     + Preprocessing (전처리)                            │
│     + Model Inference (모델 추론)                       │
│     + Network (네트워크, 클라우드인 경우)               │
│     + Postprocessing (후처리)                           │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   🎯 목표:                                              │
│   • 실시간 자막: < 500ms                               │
│   • 음성 비서: < 1000ms                                │
│   • 오프라인 처리: 제한 없음                           │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### STT 실시간 최적화

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🚀 STT Latency 줄이는 방법                            │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   1. 스트리밍 처리                                      │
│   ═══════════════════════════════════════════════════   │
│                                                         │
│   ❌ 전체 대기:  [──────전체 녹음──────] → 처리 → 결과  │
│                                                         │
│   ✅ 스트리밍:   [청크1] → 결과1                        │
│                 [청크2] → 결과2 (수정)                  │
│                 [청크3] → 결과3 (최종)                  │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   2. 작은 모델 사용                                     │
│   ═══════════════════════════════════════════════════   │
│                                                         │
│   Whisper large: 정확하지만 느림                       │
│   Whisper tiny:  약간 덜 정확하지만 5배 빠름           │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   3. 하드웨어 가속                                      │
│   ═══════════════════════════════════════════════════   │
│                                                         │
│   CPU → GPU → 전용 NPU (Neural Processing Unit)        │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### TTS 실시간 최적화

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🚀 TTS Latency 줄이는 방법                            │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   1. 문장 단위 스트리밍                                 │
│   ═══════════════════════════════════════════════════   │
│                                                         │
│   "안녕하세요. 오늘 날씨가 좋네요. 산책 어때요?"        │
│                                                         │
│   ❌ 전체 생성 후 재생                                  │
│   ✅ 문장별로 생성하며 재생                             │
│      "안녕하세요." → 🔊 (재생하는 동안 다음 문장 생성)  │
│      "오늘 날씨가 좋네요." → 🔊                        │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   2. 캐싱                                               │
│   ═══════════════════════════════════════════════════   │
│                                                         │
│   자주 쓰는 문구 미리 생성해두기                        │
│   예: "안녕하세요", "감사합니다", "잠시만요"            │
│                                                         │
│   ═══════════════════════════════════════════════════   │
│   3. 경량 모델 선택                                     │
│   ═══════════════════════════════════════════════════   │
│                                                         │
│   • FastSpeech 2: 비자기회귀, 빠름                     │
│   • VITS: End-to-End, 효율적                           │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### 노이즈 데이터 대응

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🔊 노이즈 유형별 대응 전략                             │
│                                                         │
│   ┌─────────────────┬───────────────────────────────┐  │
│   │ 노이즈 유형     │ 대응 방법                     │  │
│   ├─────────────────┼───────────────────────────────┤  │
│   │ 백색 소음       │ Spectral Subtraction          │  │
│   │ (에어컨, 팬)    │ 주파수 영역에서 제거          │  │
│   ├─────────────────┼───────────────────────────────┤  │
│   │ 배경 음악       │ 음성/음악 분리 모델           │  │
│   │                 │ (Demucs 등)                   │  │
│   ├─────────────────┼───────────────────────────────┤  │
│   │ 다중 화자       │ 화자 분리                     │  │
│   │ (여러 명 동시)  │ (Speaker Diarization)         │  │
│   ├─────────────────┼───────────────────────────────┤  │
│   │ 반향/에코       │ Dereverberation               │  │
│   │ (넓은 공간)     │ 잔향 제거                     │  │
│   └─────────────────┴───────────────────────────────┘  │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   💡 가장 효과적인 방법:                                │
│   노이즈 섞인 데이터로 모델 학습 (Data Augmentation)    │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### Data Augmentation (데이터 증강)

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   🔄 학습 데이터 증강 기법                               │
│                                                         │
│   원본 오디오 하나로 여러 변형 생성:                     │
│                                                         │
│   ┌─────────────────────────────────────────────────┐  │
│   │                                                 │  │
│   │  [원본] ──┬──▶ + 노이즈 추가                   │  │
│   │          │                                     │  │
│   │          ├──▶ 속도 변경 (0.9x ~ 1.1x)         │  │
│   │          │                                     │  │
│   │          ├──▶ 피치 변경 (±2 반음)             │  │
│   │          │                                     │  │
│   │          ├──▶ 볼륨 조절                        │  │
│   │          │                                     │  │
│   │          └──▶ 반향 추가 (Room Simulation)     │  │
│   │                                                 │  │
│   └─────────────────────────────────────────────────┘  │
│                                                         │
│   💡 효과:                                              │
│   • 다양한 환경에 강건한 모델                           │
│   • 학습 데이터 부족 문제 해결                          │
│   • 과적합(Overfitting) 방지                           │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

### 실무 체크리스트

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   ✅ STT 서비스 체크리스트                              │
│                                                         │
│   □ 샘플링 레이트 확인 (16kHz 권장)                     │
│   □ 오디오 포맷 통일 (16-bit PCM)                       │
│   □ 묵음 구간 처리 정책 결정                            │
│   □ 실시간 vs 배치 처리 결정                            │
│   □ 오류 복구 메커니즘 구현                             │
│   □ 언어/방언 지원 범위 정의                            │
│   □ 개인정보 처리 정책 (음성 데이터)                    │
│                                                         │
│   ───────────────────────────────────────────────────   │
│                                                         │
│   ✅ TTS 서비스 체크리스트                              │
│                                                         │
│   □ 텍스트 정규화 규칙 정의                             │
│   □ G2P 커버리지 테스트                                 │
│   □ 음성 스타일/감정 지원 여부                          │
│   □ 출력 포맷 결정 (WAV, MP3)                          │
│   □ 스트리밍 지원 여부                                  │
│   □ SSML 지원 여부 (마크업 제어)                       │
│   □ 저작권 확인 (음성 데이터/모델)                      │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## 📸 [시각화 자료 슬라이드]

### 추천 시각화 자료 목록

| 자료 | 설명 | 활용 |
|------|------|------|
| **WER/CER 계산 예시** | 단계별 계산 과정 | 지표 이해 |
| **MOS 점수 분포** | 모델별 MOS 비교 그래프 | TTS 품질 비교 |
| **Latency 구성도** | 구간별 소요 시간 파이 차트 | 최적화 포인트 |
| **노이즈 유형 파형** | 각 노이즈의 특징 | 노이즈 이해 |
| **Data Augmentation** | 변형 전후 스펙트로그램 | 증강 효과 |

---

## 🎯 Chapter 4 핵심 요약

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   📌 기억해야 할 것들                                    │
│                                                         │
│   1. STT 평가: WER (영어), CER (한국어)                 │
│                                                         │
│   2. TTS 평가: MOS (1~5점 인간 평가)                    │
│      - 4.0 이상이면 사람에 근접                         │
│                                                         │
│   3. Latency: 실시간이면 스트리밍 필수                  │
│      - 모델 크기, 하드웨어 선택 중요                    │
│                                                         │
│   4. 노이즈 대응: 전처리 + Data Augmentation            │
│                                                         │
│   5. 실무 체크리스트 꼭 확인!                           │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

# 📚 부록

## A. 주요 라이브러리/서비스

### STT

| 이름 | 특징 | 비용 |
|------|------|------|
| **OpenAI Whisper** | 다국어, 고품질, 오픈소스 | 무료 (로컬) |
| **Google Speech-to-Text** | 안정적, 스트리밍 | 유료 (API) |
| **Naver Clova Speech** | 한국어 최적화 | 유료 (API) |
| **AWS Transcribe** | AWS 통합 | 유료 (API) |

### TTS

| 이름 | 특징 | 비용 |
|------|------|------|
| **Coqui TTS** | 오픈소스, 다양한 모델 | 무료 (로컬) |
| **Google Cloud TTS** | 다국어, WaveNet | 유료 (API) |
| **Naver Clova Voice** | 한국어 감정 표현 | 유료 (API) |
| **ElevenLabs** | 고품질 음성 복제 | 유료 (API) |

---

## B. 참고 자료

### 논문 (읽어보면 좋은 것들)

1. **Attention Is All You Need** (2017) - Transformer의 시작
2. **Wav2Vec 2.0** (2020) - 자기지도학습 STT
3. **Whisper** (2022) - 대규모 다국어 STT
4. **HiFi-GAN** (2020) - 실시간 고품질 Vocoder
5. **VITS** (2021) - End-to-End TTS

### 학습 자료

- Hugging Face Audio Course (무료)
- Google ML 오디오 과정
- 논문 리뷰 유튜브 채널들

---

## C. 용어 정리

| 용어 | 설명 |
|------|------|
| **Alignment** | 입력-출력 시퀀스 간 대응 관계 |
| **Attention** | 입력의 어디에 집중할지 학습하는 메커니즘 |
| **Blank (ε)** | CTC에서 사용하는 빈 토큰 |
| **CTC** | Connectionist Temporal Classification |
| **G2P** | Grapheme to Phoneme (문자→발음) |
| **Mel Scale** | 인간 청각 기반 주파수 스케일 |
| **MOS** | Mean Opinion Score (1~5점 평가) |
| **Spectrogram** | 시간-주파수 에너지 표현 |
| **STFT** | Short-Time Fourier Transform |
| **Vocoder** | 음향 특성 → 오디오 파형 변환기 |
| **WER/CER** | Word/Character Error Rate |

---

> 📅 **세미나 일시**: 2024년 12월 20일
> 
> 👤 **강사**: [강사명]
> 
> 📧 **문의**: [연락처]
