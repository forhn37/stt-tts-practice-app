# ğŸ› ï¸ SoundLab ì‹¤ìŠµ ì•± ê°œë°œ ê³„íšì„œ v3 (ì‹¤ì „ ê°œë°œìš©)

> **ë²„ì „**: 3.0 (VSCode ê°œë°œ ì¤€ë¹„ ì™„ë£Œ)
> 
> **ë³€ê²½ì‚¬í•­**: ê¸°ì¡´ v2 ê²€í†  í›„ ì‹¤í˜„ ê°€ëŠ¥ì„± ì¬ì ê²€, ì¦‰ì‹œ ê°œë°œ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ìˆ˜ì •

---

## ğŸ” ê¸°ì¡´ ê³„íšì„œ(v2) ì ê²€ ê²°ê³¼

### âœ… ìœ ì§€í•  ê²ƒ
- Frontend Only ì•„í‚¤í…ì²˜ (Vercel ë¬´ë£Œ ë°°í¬)
- React + TypeScript + Vite + Tailwind
- Web Audio API / Web Speech API í™œìš©
- 4ê°œ ëª¨ë“ˆ êµ¬ì¡° (Wave Lab, STT Lab, TTS Lab, Playground)

### âš ï¸ ìˆ˜ì •ì´ í•„ìš”í•œ ê²ƒ

| í•­ëª© | ê¸°ì¡´ ê³„íš | ë¬¸ì œì  | ìˆ˜ì • |
|------|----------|--------|------|
| **Meyda.js** | Mel-Spectrogram ìƒì„± | `melBands`ë§Œ ì œê³µ, full spectrogram ì•„ë‹˜ | ì§ì ‘ Canvasë¡œ êµ¬í˜„ (ë” ê°„ë‹¨) |
| **D3.js** | Beam Search íŠ¸ë¦¬ | Reactì™€ ì¡°í•© ë³µì¡ | **react-d3-tree** ë˜ëŠ” ìˆœìˆ˜ SVG |
| **Recharts** | FFT ê·¸ë˜í”„ | ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì„±ëŠ¥ ì´ìŠˆ | **Canvas ì§ì ‘ ë Œë”ë§** (ë” ë¹ ë¦„) |
| **í”„ë¡œì íŠ¸ êµ¬ì¡°** | 15ê°œ+ ì»´í¬ë„ŒíŠ¸ | ê³¼ë„í•˜ê²Œ ë¶„ë¦¬ë¨ | **8ê°œ í•µì‹¬ ì»´í¬ë„ŒíŠ¸**ë¡œ ë‹¨ìˆœí™” |
| **G2P êµ¬í˜„** | ê·œì¹™ ê¸°ë°˜ ë”•ì…”ë„ˆë¦¬ | ì»¤ë²„ë¦¬ì§€ ë¶€ì¡± | **ëŒ€í‘œ ì˜ˆì‹œ 30ê°œ + ì„¤ëª…** ìœ„ì£¼ |

### âŒ ì œê±°/ì¶•ì†Œí•  ê²ƒ
- Attention íˆíŠ¸ë§µ (ì‹¤ì‹œê°„ ìƒì„± ë¶ˆê°€ â†’ ì •ì  ì´ë¯¸ì§€ë¡œ ëŒ€ì²´)
- Vocoder ë¹„êµ (ìƒ˜í”Œ ì˜¤ë””ì˜¤ ì¬ìƒë§Œ)
- ë³µì¡í•œ Text Normalization (ê°„ë‹¨í•œ ì˜ˆì‹œë§Œ)

---

## ğŸ“ ìˆ˜ì •ëœ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
soundlab/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ layout/
â”‚   â”‚   â”‚   â”œâ”€â”€ Header.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ TabNav.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Footer.tsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ WaveLab/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.tsx              # íƒ­ ì»¨í…Œì´ë„ˆ
â”‚   â”‚   â”‚   â”œâ”€â”€ WaveformCanvas.tsx     # ì‹¤ì‹œê°„ íŒŒí˜• (Canvas)
â”‚   â”‚   â”‚   â”œâ”€â”€ FFTCanvas.tsx          # ì£¼íŒŒìˆ˜ ë¶„ì„ (Canvas)
â”‚   â”‚   â”‚   â””â”€â”€ SpectrogramCanvas.tsx  # ìŠ¤í™íŠ¸ë¡œê·¸ë¨ (Canvas)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ STTLab/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.tsx              # íƒ­ ì»¨í…Œì´ë„ˆ
â”‚   â”‚   â”‚   â”œâ”€â”€ CTCSimulator.tsx       # CTC ë””ì½”ë”© ì‹œë®¬ë ˆì´ì…˜
â”‚   â”‚   â”‚   â”œâ”€â”€ SpeechRecognizer.tsx   # Web Speech API STT
â”‚   â”‚   â”‚   â””â”€â”€ BeamSearchDemo.tsx     # Beam Search ì‹œê°í™” (SVG)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ TTSLab/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.tsx              # íƒ­ ì»¨í…Œì´ë„ˆ
â”‚   â”‚   â”‚   â”œâ”€â”€ G2PDemo.tsx            # G2P ë³€í™˜ ë°ëª¨
â”‚   â”‚   â”‚   â””â”€â”€ SpeechSynthesizer.tsx  # Web Speech API TTS
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ Playground/
â”‚   â”‚       â”œâ”€â”€ index.tsx              # íƒ­ ì»¨í…Œì´ë„ˆ
â”‚   â”‚       â”œâ”€â”€ STTTTSCycle.tsx        # STTâ†’TTS ìˆœí™˜
â”‚   â”‚       â””â”€â”€ MetricsDemo.tsx        # WER/CER ê³„ì‚°
â”‚   â”‚
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useAudioContext.ts         # Web Audio ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ useMediaRecorder.ts        # ë…¹ìŒ ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ useSpeechRecognition.ts    # STT í›…
â”‚   â”‚   â””â”€â”€ useSpeechSynthesis.ts      # TTS í›…
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ audioUtils.ts              # FFT, íŒŒí˜• ë°ì´í„° ì²˜ë¦¬
â”‚   â”‚   â”œâ”€â”€ ctcDecoder.ts              # CTC ë¡œì§
â”‚   â”‚   â”œâ”€â”€ g2pRules.ts                # í•œêµ­ì–´ G2P ê·œì¹™
â”‚   â”‚   â””â”€â”€ metrics.ts                 # WER/CER ê³„ì‚°
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ g2pExamples.ts             # G2P ì˜ˆì‹œ ë°ì´í„°
â”‚   â”‚
â”‚   â”œâ”€â”€ App.tsx
â”‚   â”œâ”€â”€ main.tsx
â”‚   â””â”€â”€ index.css                      # Tailwind ì§„ì…ì 
â”‚
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ samples/
â”‚   â”‚   â”œâ”€â”€ griffin_lim.mp3            # Griffin-Lim ìƒ˜í”Œ
â”‚   â”‚   â””â”€â”€ hifigan.mp3                # HiFi-GAN ìƒ˜í”Œ
â”‚   â””â”€â”€ images/
â”‚       â””â”€â”€ attention_heatmap.png      # ì •ì  Attention ì´ë¯¸ì§€
â”‚
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ vite.config.ts
â”œâ”€â”€ tailwind.config.js
â”œâ”€â”€ postcss.config.js
â””â”€â”€ vercel.json
```

**ì»´í¬ë„ŒíŠ¸ ìˆ˜**: 15ê°œ â†’ **12ê°œ** (30% ê°ì†Œ)

---

## ğŸ“¦ package.json (ë³µì‚¬í•´ì„œ ë°”ë¡œ ì‚¬ìš©)

```json
{
  "name": "soundlab",
  "version": "1.0.0",
  "private": true,
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "tsc && vite build",
    "preview": "vite preview",
    "lint": "eslint . --ext ts,tsx"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "lucide-react": "^0.294.0"
  },
  "devDependencies": {
    "@types/react": "^18.2.43",
    "@types/react-dom": "^18.2.17",
    "@vitejs/plugin-react": "^4.2.1",
    "autoprefixer": "^10.4.16",
    "eslint": "^8.55.0",
    "eslint-plugin-react-hooks": "^4.6.0",
    "postcss": "^8.4.32",
    "tailwindcss": "^3.3.6",
    "typescript": "^5.3.3",
    "vite": "^5.0.8"
  }
}
```

### ğŸ“Œ ì˜ì¡´ì„± ì„¤ëª…

| íŒ¨í‚¤ì§€ | ë²„ì „ | ìš©ë„ |
|--------|------|------|
| react | 18.2.0 | UI í”„ë ˆì„ì›Œí¬ |
| lucide-react | 0.294.0 | ì•„ì´ì½˜ (ê²½ëŸ‰) |
| tailwindcss | 3.3.6 | ìŠ¤íƒ€ì¼ë§ |
| vite | 5.0.8 | ë¹Œë“œ ë„êµ¬ |

**ì œê±°ëœ íŒ¨í‚¤ì§€**:
- ~~recharts~~ â†’ Canvas ì§ì ‘ ì‚¬ìš©
- ~~d3~~ â†’ SVG ì§ì ‘ ì‚¬ìš© ë˜ëŠ” ê°„ë‹¨í•œ íŠ¸ë¦¬ êµ¬í˜„
- ~~meyda~~ â†’ Web Audio APIë¡œ ì¶©ë¶„

---

## ğŸš€ VSCodeì—ì„œ ì‹œì‘í•˜ê¸°

### Step 1: í”„ë¡œì íŠ¸ ìƒì„±

```bash
# 1. Viteë¡œ React + TypeScript í”„ë¡œì íŠ¸ ìƒì„±
npm create vite@latest soundlab -- --template react-ts

# 2. í´ë” ì´ë™
cd soundlab

# 3. ì˜ì¡´ì„± ì„¤ì¹˜
npm install

# 4. Tailwind ì„¤ì¹˜
npm install -D tailwindcss postcss autoprefixer
npx tailwindcss init -p

# 5. ì•„ì´ì½˜ ì„¤ì¹˜
npm install lucide-react

# 6. ê°œë°œ ì„œë²„ ì‹œì‘
npm run dev
```

### Step 2: Tailwind ì„¤ì •

**tailwind.config.js**:
```javascript
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {
      colors: {
        primary: '#4F46E5',    // ì¸ë””ê³ 
        secondary: '#06B6D4',  // ì‹œì•ˆ
        accent: '#F59E0B',     // ì•°ë²„
      }
    },
  },
  plugins: [],
}
```

**src/index.css**:
```css
@tailwind base;
@tailwind components;
@tailwind utilities;

/* ì»¤ìŠ¤í…€ ìŠ¤íƒ€ì¼ */
body {
  @apply bg-gray-50 text-gray-900;
}
```

### Step 3: í•µì‹¬ ì„¤ì • íŒŒì¼ë“¤

**vite.config.ts**:
```typescript
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

export default defineConfig({
  plugins: [react()],
  server: {
    port: 3000,
  },
})
```

**vercel.json**:
```json
{
  "buildCommand": "npm run build",
  "outputDirectory": "dist",
  "framework": "vite"
}
```

**tsconfig.json** (ìˆ˜ì • ë¶€ë¶„):
```json
{
  "compilerOptions": {
    "target": "ES2020",
    "useDefineForClassFields": true,
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "skipLibCheck": true,
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx",
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noFallthroughCasesInSwitch": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["src/*"]
    }
  },
  "include": ["src"],
  "references": [{ "path": "./tsconfig.node.json" }]
}
```

---

## ğŸ¯ ê°œë°œ ìš°ì„ ìˆœìœ„ (MVP ë¨¼ì €!)

### Phase 1: í•µì‹¬ ê¸°ëŠ¥ (3ì¼) â­ MVP

| ìˆœì„œ | ì»´í¬ë„ŒíŠ¸ | ì†Œìš” | ë‚œì´ë„ |
|------|----------|------|--------|
| 1 | App.tsx + íƒ­ ë„¤ë¹„ê²Œì´ì…˜ | 2h | â­ |
| 2 | WaveformCanvas (ì‹¤ì‹œê°„ íŒŒí˜•) | 3h | â­â­ |
| 3 | SpeechRecognizer (STT) | 2h | â­ |
| 4 | SpeechSynthesizer (TTS) | 2h | â­ |
| 5 | CTCSimulator | 3h | â­â­ |
| 6 | G2PDemo | 2h | â­ |

**Phase 1 ì™„ë£Œ ì‹œ**: ì„¸ë¯¸ë‚˜ ì‹¤ìŠµ ê°€ëŠ¥í•œ ìµœì†Œ ê¸°ëŠ¥ ì™„ì„±

### Phase 2: ì‹œê°í™” ê°•í™” (2ì¼)

| ìˆœì„œ | ì»´í¬ë„ŒíŠ¸ | ì†Œìš” | ë‚œì´ë„ |
|------|----------|------|--------|
| 7 | FFTCanvas (ì£¼íŒŒìˆ˜ ë¶„ì„) | 3h | â­â­ |
| 8 | SpectrogramCanvas | 4h | â­â­â­ |
| 9 | BeamSearchDemo | 3h | â­â­ |

### Phase 3: ì™„ì„±ë„ (1ì¼)

| ìˆœì„œ | ì»´í¬ë„ŒíŠ¸ | ì†Œìš” | ë‚œì´ë„ |
|------|----------|------|--------|
| 10 | STTTTSCycle (ìˆœí™˜ í…ŒìŠ¤íŠ¸) | 2h | â­â­ |
| 11 | MetricsDemo (WER/CER) | 2h | â­ |
| 12 | UI ë‹¤ë“¬ê¸° + ë°˜ì‘í˜• | 3h | â­ |

---

## ğŸ”§ í•µì‹¬ ì½”ë“œ ìŠ¤ë‹ˆí«

### 1. useAudioContext.ts (Web Audio í›…)

```typescript
import { useRef, useState, useCallback } from 'react';

export function useAudioContext() {
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const [isRecording, setIsRecording] = useState(false);

  const startRecording = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      audioContextRef.current = new AudioContext();
      analyserRef.current = audioContextRef.current.createAnalyser();
      analyserRef.current.fftSize = 2048;
      
      sourceRef.current = audioContextRef.current.createMediaStreamSource(stream);
      sourceRef.current.connect(analyserRef.current);
      
      setIsRecording(true);
      return { analyser: analyserRef.current, audioContext: audioContextRef.current };
    } catch (error) {
      console.error('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:', error);
      throw error;
    }
  }, []);

  const stopRecording = useCallback(() => {
    if (sourceRef.current) {
      sourceRef.current.disconnect();
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
    }
    setIsRecording(false);
  }, []);

  const getWaveformData = useCallback(() => {
    if (!analyserRef.current) return null;
    const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);
    analyserRef.current.getByteTimeDomainData(dataArray);
    return dataArray;
  }, []);

  const getFrequencyData = useCallback(() => {
    if (!analyserRef.current) return null;
    const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);
    analyserRef.current.getByteFrequencyData(dataArray);
    return dataArray;
  }, []);

  return {
    isRecording,
    startRecording,
    stopRecording,
    getWaveformData,
    getFrequencyData,
  };
}
```

### 2. useSpeechRecognition.ts (STT í›…)

```typescript
import { useState, useCallback, useRef, useEffect } from 'react';

interface SpeechRecognitionResult {
  transcript: string;
  confidence: number;
  isFinal: boolean;
}

export function useSpeechRecognition() {
  const [isListening, setIsListening] = useState(false);
  const [results, setResults] = useState<SpeechRecognitionResult[]>([]);
  const [error, setError] = useState<string | null>(null);
  const recognitionRef = useRef<SpeechRecognition | null>(null);

  useEffect(() => {
    // ë¸Œë¼ìš°ì € ì§€ì› í™•ì¸
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      setError('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chromeì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.');
      return;
    }

    recognitionRef.current = new SpeechRecognition();
    recognitionRef.current.lang = 'ko-KR';
    recognitionRef.current.continuous = true;
    recognitionRef.current.interimResults = true;

    recognitionRef.current.onresult = (event) => {
      const newResults: SpeechRecognitionResult[] = [];
      for (let i = event.resultIndex; i < event.results.length; i++) {
        newResults.push({
          transcript: event.results[i][0].transcript,
          confidence: event.results[i][0].confidence,
          isFinal: event.results[i].isFinal,
        });
      }
      setResults(prev => [...prev, ...newResults]);
    };

    recognitionRef.current.onerror = (event) => {
      setError(`ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ${event.error}`);
      setIsListening(false);
    };

    recognitionRef.current.onend = () => {
      setIsListening(false);
    };

    return () => {
      recognitionRef.current?.stop();
    };
  }, []);

  const startListening = useCallback(() => {
    setResults([]);
    setError(null);
    recognitionRef.current?.start();
    setIsListening(true);
  }, []);

  const stopListening = useCallback(() => {
    recognitionRef.current?.stop();
    setIsListening(false);
  }, []);

  return {
    isListening,
    results,
    error,
    startListening,
    stopListening,
    isSupported: !!recognitionRef.current,
  };
}
```

### 3. useSpeechSynthesis.ts (TTS í›…)

```typescript
import { useState, useCallback, useEffect } from 'react';

export function useSpeechSynthesis() {
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [voices, setVoices] = useState<SpeechSynthesisVoice[]>([]);
  const [selectedVoice, setSelectedVoice] = useState<SpeechSynthesisVoice | null>(null);

  useEffect(() => {
    const loadVoices = () => {
      const availableVoices = speechSynthesis.getVoices();
      setVoices(availableVoices);
      
      // í•œêµ­ì–´ ìŒì„± ê¸°ë³¸ ì„ íƒ
      const koreanVoice = availableVoices.find(v => v.lang.includes('ko'));
      if (koreanVoice) setSelectedVoice(koreanVoice);
    };

    loadVoices();
    speechSynthesis.onvoiceschanged = loadVoices;
  }, []);

  const speak = useCallback((text: string, rate = 1, pitch = 1) => {
    if (isSpeaking) {
      speechSynthesis.cancel();
    }

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'ko-KR';
    utterance.rate = rate;
    utterance.pitch = pitch;
    
    if (selectedVoice) {
      utterance.voice = selectedVoice;
    }

    utterance.onstart = () => setIsSpeaking(true);
    utterance.onend = () => setIsSpeaking(false);
    utterance.onerror = () => setIsSpeaking(false);

    speechSynthesis.speak(utterance);
  }, [isSpeaking, selectedVoice]);

  const stop = useCallback(() => {
    speechSynthesis.cancel();
    setIsSpeaking(false);
  }, []);

  return {
    isSpeaking,
    voices,
    selectedVoice,
    setSelectedVoice,
    speak,
    stop,
  };
}
```

### 4. ctcDecoder.ts (CTC ë¡œì§)

```typescript
export interface CTCStep {
  step: number;
  description: string;
  sequence: string[];
  result: string;
}

export function ctcDecode(input: string[]): CTCStep[] {
  const steps: CTCStep[] = [];
  
  // Step 0: ì›ë³¸ ì…ë ¥
  steps.push({
    step: 0,
    description: 'Raw CTC Output',
    sequence: [...input],
    result: input.join('-'),
  });

  // Step 1: ì—°ì† ì¤‘ë³µ ì œê±°
  const collapsed: string[] = [];
  let prev: string | null = null;
  for (const char of input) {
    if (char !== prev) {
      collapsed.push(char);
      prev = char;
    }
  }
  steps.push({
    step: 1,
    description: 'Collapse Consecutive Duplicates',
    sequence: [...collapsed],
    result: collapsed.join('-'),
  });

  // Step 2: Blank ì œê±°
  const final = collapsed.filter(c => c !== 'Îµ' && c !== '-' && c !== 'blank');
  steps.push({
    step: 2,
    description: 'Remove Blanks (Îµ)',
    sequence: [...final],
    result: final.join(''),
  });

  return steps;
}

// ëœë¤ CTC ì¶œë ¥ ìƒì„± (ë°ëª¨ìš©)
export function generateRandomCTC(targetWord: string): string[] {
  const result: string[] = [];
  for (const char of targetWord) {
    // ëœë¤í•˜ê²Œ blank ì¶”ê°€
    if (Math.random() > 0.5) result.push('Îµ');
    // ëœë¤í•˜ê²Œ ì¤‘ë³µ ì¶”ê°€
    const repeatCount = Math.floor(Math.random() * 3) + 1;
    for (let i = 0; i < repeatCount; i++) {
      result.push(char);
    }
  }
  result.push('Îµ');
  return result;
}
```

### 5. g2pRules.ts (G2P ê·œì¹™)

```typescript
export interface G2PExample {
  input: string;
  output: string;
  rule: string;
  ruleKo: string;
  description: string;
}

export const g2pExamples: G2PExample[] = [
  // êµ¬ê°œìŒí™”
  { input: 'ê°™ì´', output: 'ê°€ì¹˜', rule: 'Palatalization', ruleKo: 'êµ¬ê°œìŒí™”', description: 'ã„·/ã…Œ + ì´ â†’ ã…ˆ/ã…Š' },
  { input: 'êµ³ì´', output: 'êµ¬ì§€', rule: 'Palatalization', ruleKo: 'êµ¬ê°œìŒí™”', description: 'ã„· + ì´ â†’ ã…ˆ' },
  { input: 'ë¶™ì´ë‹¤', output: 'ë¶€ì¹˜ë‹¤', rule: 'Palatalization', ruleKo: 'êµ¬ê°œìŒí™”', description: 'ã…Œ + ì´ â†’ ã…Š' },
  { input: 'í•´ë‹ì´', output: 'í•´ë„ì§€', rule: 'Palatalization', ruleKo: 'êµ¬ê°œìŒí™”', description: 'ã„· + ì´ â†’ ã…ˆ' },
  
  // ê²½ìŒí™”
  { input: 'í•™êµ', output: 'í•™ê¾œ', rule: 'Fortition', ruleKo: 'ê²½ìŒí™”', description: 'ã„± + ã„± â†’ ã„± + ã„²' },
  { input: 'êµ­ë°¥', output: 'êµ­ë¹±', rule: 'Fortition', ruleKo: 'ê²½ìŒí™”', description: 'ã„± + ã…‚ â†’ ã„± + ã…ƒ' },
  { input: 'ì‹ë‹¹', output: 'ì‹ë•…', rule: 'Fortition', ruleKo: 'ê²½ìŒí™”', description: 'ã„± + ã„· â†’ ã„± + ã„¸' },
  { input: 'ì…êµ¬', output: 'ì…ê¾¸', rule: 'Fortition', ruleKo: 'ê²½ìŒí™”', description: 'ã…‚ + ã„± â†’ ã…‚ + ã„²' },
  
  // ë¹„ìŒí™”
  { input: 'êµ­ë¯¼', output: 'ê¶ë¯¼', rule: 'Nasalization', ruleKo: 'ë¹„ìŒí™”', description: 'ã„± + ã… â†’ ã…‡ + ã…' },
  { input: 'ê°‘ë‹ˆë‹¤', output: 'ê°ë‹ˆë‹¤', rule: 'Nasalization', ruleKo: 'ë¹„ìŒí™”', description: 'ã…‚ + ã„´ â†’ ã… + ã„´' },
  { input: 'ìˆëŠ”', output: 'ì¸ëŠ”', rule: 'Nasalization', ruleKo: 'ë¹„ìŒí™”', description: 'ã…† + ã„´ â†’ ã„´ + ã„´' },
  { input: 'ë§ëˆ„ë‚˜', output: 'ë§Œëˆ„ë‚˜', rule: 'Nasalization', ruleKo: 'ë¹„ìŒí™”', description: 'ã„· + ã„´ â†’ ã„´ + ã„´' },
  
  // ì—°ìŒ
  { input: 'ìŒì•…ì„', output: 'ìœ¼ë§ˆê¸€', rule: 'Liaison', ruleKo: 'ì—°ìŒ', description: 'ë°›ì¹¨ + ëª¨ìŒ â†’ ì—°ìŒ' },
  { input: 'ì˜·ì„', output: 'ì˜¤ìŠ¬', rule: 'Liaison', ruleKo: 'ì—°ìŒ', description: 'ã……ë°›ì¹¨ ì—°ìŒ' },
  { input: 'ë°–ì—', output: 'ë°”ê»˜', rule: 'Liaison', ruleKo: 'ì—°ìŒ', description: 'ã„±ë°›ì¹¨ ì—°ìŒ + ê²½ìŒí™”' },
  { input: 'ê½ƒì´', output: 'ê¼¬ì¹˜', rule: 'Liaison', ruleKo: 'ì—°ìŒ', description: 'ã…Šë°›ì¹¨ ì—°ìŒ' },
  
  // ã… íƒˆë½
  { input: 'ì¢‹ì•„', output: 'ì¡°ì•„', rule: 'H-deletion', ruleKo: 'ã…íƒˆë½', description: 'ã… + ëª¨ìŒ â†’ íƒˆë½' },
  { input: 'ë†“ì•„', output: 'ë…¸ì•„', rule: 'H-deletion', ruleKo: 'ã…íƒˆë½', description: 'ã… + ì•„ â†’ ì•„' },
  { input: 'ë„£ì–´', output: 'ë„ˆì–´', rule: 'H-deletion', ruleKo: 'ã…íƒˆë½', description: 'ã… + ì–´ â†’ ì–´' },
  
  // ê²©ìŒí™”
  { input: 'ì¶•í•˜', output: 'ì¶”ì¹´', rule: 'Aspiration', ruleKo: 'ê²©ìŒí™”', description: 'ã„± + ã… â†’ ã…‹' },
  { input: 'ì…í•™', output: 'ì´íŒ', rule: 'Aspiration', ruleKo: 'ê²©ìŒí™”', description: 'ã…‚ + ã… â†’ ã…' },
  { input: 'ëª»í•˜ë‹¤', output: 'ëª¨íƒ€ë‹¤', rule: 'Aspiration', ruleKo: 'ê²©ìŒí™”', description: 'ã„· + ã… â†’ ã…Œ' },
];

// ê°„ë‹¨í•œ G2P ë³€í™˜ (ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜)
const g2pDict: Record<string, string> = {};
g2pExamples.forEach(ex => {
  g2pDict[ex.input] = ex.output;
});

export function simpleG2P(text: string): string {
  let result = text;
  for (const [input, output] of Object.entries(g2pDict)) {
    result = result.replace(new RegExp(input, 'g'), output);
  }
  return result;
}

// ê·œì¹™ë³„ ê·¸ë£¹í™”
export function getExamplesByRule(): Record<string, G2PExample[]> {
  const grouped: Record<string, G2PExample[]> = {};
  g2pExamples.forEach(ex => {
    if (!grouped[ex.ruleKo]) {
      grouped[ex.ruleKo] = [];
    }
    grouped[ex.ruleKo].push(ex);
  });
  return grouped;
}
```

### 6. metrics.ts (WER/CER ê³„ì‚°)

```typescript
// Levenshtein Distance
function levenshteinDistance<T>(a: T[], b: T[]): number {
  const matrix: number[][] = Array(b.length + 1)
    .fill(null)
    .map(() => Array(a.length + 1).fill(null));

  for (let i = 0; i <= a.length; i++) matrix[0][i] = i;
  for (let j = 0; j <= b.length; j++) matrix[j][0] = j;

  for (let j = 1; j <= b.length; j++) {
    for (let i = 1; i <= a.length; i++) {
      const cost = a[i - 1] === b[j - 1] ? 0 : 1;
      matrix[j][i] = Math.min(
        matrix[j][i - 1] + 1,       // ì‚½ì…
        matrix[j - 1][i] + 1,       // ì‚­ì œ
        matrix[j - 1][i - 1] + cost // ëŒ€ì²´
      );
    }
  }

  return matrix[b.length][a.length];
}

export interface MetricResult {
  value: number;
  percentage: string;
  details: {
    substitutions: number;
    deletions: number;
    insertions: number;
    total: number;
  };
}

export function calculateWER(reference: string, hypothesis: string): MetricResult {
  const refWords = reference.trim().split(/\s+/);
  const hypWords = hypothesis.trim().split(/\s+/);
  const distance = levenshteinDistance(refWords, hypWords);
  const value = distance / refWords.length;
  
  return {
    value,
    percentage: (value * 100).toFixed(2) + '%',
    details: {
      substitutions: 0, // ìƒì„¸ ê³„ì‚°ì€ ë³µì¡í•´ì„œ ìƒëµ
      deletions: 0,
      insertions: 0,
      total: distance,
    },
  };
}

export function calculateCER(reference: string, hypothesis: string): MetricResult {
  const refChars = [...reference.replace(/\s/g, '')];
  const hypChars = [...hypothesis.replace(/\s/g, '')];
  const distance = levenshteinDistance(refChars, hypChars);
  const value = distance / refChars.length;
  
  return {
    value,
    percentage: (value * 100).toFixed(2) + '%',
    details: {
      substitutions: 0,
      deletions: 0,
      insertions: 0,
      total: distance,
    },
  };
}
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­ & íŒ

### ë¸Œë¼ìš°ì € í˜¸í™˜ì„±

```typescript
// ë°˜ë“œì‹œ ì²´í¬í•´ì•¼ í•  ê²ƒë“¤
const checkBrowserSupport = () => {
  const support = {
    webAudio: typeof AudioContext !== 'undefined',
    speechRecognition: 'SpeechRecognition' in window || 'webkitSpeechRecognition' in window,
    speechSynthesis: 'speechSynthesis' in window,
    getUserMedia: 'mediaDevices' in navigator,
  };
  
  return support;
};
```

### ë§ˆì´í¬ ê¶Œí•œ ì²˜ë¦¬

```typescript
// ê¶Œí•œ ê±°ë¶€ ì‹œ ì¹œì ˆí•œ ì•ˆë‚´
const handleMicPermission = async () => {
  try {
    await navigator.mediaDevices.getUserMedia({ audio: true });
    return true;
  } catch (error) {
    if (error instanceof DOMException) {
      if (error.name === 'NotAllowedError') {
        alert('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
      } else if (error.name === 'NotFoundError') {
        alert('ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.');
      }
    }
    return false;
  }
};
```

### Canvas ì„±ëŠ¥ ìµœì í™”

```typescript
// requestAnimationFrame ì‚¬ìš©
const drawWaveform = (analyser: AnalyserNode, canvas: HTMLCanvasElement) => {
  const ctx = canvas.getContext('2d')!;
  const dataArray = new Uint8Array(analyser.frequencyBinCount);
  
  const draw = () => {
    analyser.getByteTimeDomainData(dataArray);
    
    ctx.fillStyle = '#1f2937';
    ctx.fillRect(0, 0, canvas.width, canvas.height);
    
    ctx.lineWidth = 2;
    ctx.strokeStyle = '#4F46E5';
    ctx.beginPath();
    
    const sliceWidth = canvas.width / dataArray.length;
    let x = 0;
    
    for (let i = 0; i < dataArray.length; i++) {
      const v = dataArray[i] / 128.0;
      const y = (v * canvas.height) / 2;
      
      if (i === 0) {
        ctx.moveTo(x, y);
      } else {
        ctx.lineTo(x, y);
      }
      x += sliceWidth;
    }
    
    ctx.stroke();
    requestAnimationFrame(draw);
  };
  
  draw();
};
```

---

## ğŸ“… ìˆ˜ì •ëœ ê°œë°œ ì¼ì •

| Phase | ê¸°ê°„ | ëª©í‘œ | ì²´í¬í¬ì¸íŠ¸ |
|-------|------|------|-----------|
| **Phase 1** | 2ì¼ | MVP ì™„ì„± | STT/TTS ì‘ë™, CTC ì‹œë®¬ë ˆì´í„° |
| **Phase 2** | 2ì¼ | ì‹œê°í™” | íŒŒí˜•, FFT, ìŠ¤í™íŠ¸ë¡œê·¸ë¨ |
| **Phase 3** | 1ì¼ | ë§ˆë¬´ë¦¬ | UI ë‹¤ë“¬ê¸°, í…ŒìŠ¤íŠ¸, ë°°í¬ |

**ì´ 5ì¼** (ê¸°ì¡´ 7ì¼ â†’ 2ì¼ ë‹¨ì¶•)

---

## âœ… ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ê°œë°œ ì‹œì‘ ì „
- [ ] Node.js 18+ ì„¤ì¹˜ í™•ì¸
- [ ] VSCode ì„¤ì¹˜ + í™•ì¥ (ES7 React, Tailwind CSS IntelliSense)
- [ ] Chrome DevTools ì‚¬ìš©ë²• ìˆ™ì§€

### Phase 1 ì™„ë£Œ í›„ (MVP)
- [ ] Chromeì—ì„œ STT ë™ì‘ í™•ì¸
- [ ] TTS ë™ì‘ í™•ì¸
- [ ] CTC ì‹œë®¬ë ˆì´í„° ë™ì‘ í™•ì¸
- [ ] ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ ì‹œ ì•ˆë‚´ ë©”ì‹œì§€

### ë°°í¬ ì „
- [ ] Vercel ê³„ì • ìƒì„±
- [ ] ë¹Œë“œ ì„±ê³µ í™•ì¸ (`npm run build`)
- [ ] ëª¨ë°”ì¼ì—ì„œ ì ‘ì† í…ŒìŠ¤íŠ¸ (ì„ íƒ)

### ì„¸ë¯¸ë‚˜ ì „
- [ ] ì‹¤ì œ URL í…ŒìŠ¤íŠ¸
- [ ] ë°±ì—…ìš© ìŠ¤í¬ë¦°ìƒ· ì¤€ë¹„
- [ ] "Chrome ì‚¬ìš©í•´ì£¼ì„¸ìš”" ì•ˆë‚´ ë¬¸êµ¬ ì¤€ë¹„

---

> ğŸ“ **ë¬¸ì„œ ë²„ì „**: 3.0 (ì‹¤ì „ ê°œë°œìš©)
> 
> ğŸ“… **ì‘ì„±ì¼**: 2024ë…„ 12ì›”
> 
> ğŸ”„ **ì£¼ìš” ë³€ê²½**: 
> - ë¶ˆí•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì œê±°
> - ì»´í¬ë„ŒíŠ¸ ìˆ˜ 30% ê°ì†Œ
> - í•µì‹¬ ì½”ë“œ ìŠ¤ë‹ˆí« ì¶”ê°€
> - ê°œë°œ ì¼ì • ë‹¨ì¶• (7ì¼ â†’ 5ì¼)
